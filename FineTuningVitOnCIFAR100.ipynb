{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "torch.random.manual_seed(1904)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SummaryWriter for Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ViTImageProcessor from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform and Format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data using the ViTImageProcesor\n",
    "# and format it to be feasable for Hugging Face framework\n",
    "\n",
    "def transform_function(image):\n",
    "    return processor(image, return_tensors=\"pt\").pixel_values[0]\n",
    "\n",
    "class CIFAR100Dataset(torchvision.datasets.CIFAR100):\n",
    "    def __getitem__(self, index):\n",
    "        image, label = super().__getitem__(index)\n",
    "        item = {\n",
    "            'pixel_values': transform_function(image),\n",
    "            'labels': label\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data import random_split\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "train_set = CIFAR100Dataset(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "ds_train, ds_valid = random_split(train_set, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    "    )\n",
    "\n",
    "ds_test = CIFAR100Dataset(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "labels_path = \"data/cifar-100-python/meta\"\n",
    "with open(labels_path, 'rb') as f:\n",
    "    classes = pickle.load(f)['fine_label_names']\n",
    "    n_classes = len(classes)\n",
    "\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels\n",
    "id2label = {id: label for id, label in enumerate(classes)}\n",
    "label2id = {label: id for id, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot random train examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(images):\n",
    "    # Add the images to the tansorboard\n",
    "    writer.add_image('batch_images', images)\n",
    "    writer.close()\n",
    "    \n",
    "    image_np = images.permute(1, 2, 0).numpy()\n",
    "    image_np = np.clip(image_np, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "example_batch = next(iter(dl_train))\n",
    "imshow(torchvision.utils.make_grid(example_batch['pixel_values']))\n",
    "print([id2label[label.item()] for label in example_batch['labels']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the ViTForImageClassification model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model_name = 'google/vit-base-patch16-224-in21k'\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=n_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    )\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Add model architecture to the tensorboard\n",
    "writer.add_graph(model, example_batch['pixel_values'].to(DEVICE), use_strict_trace=False)\n",
    "writer.close()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from transformers import TrainerCallback, Trainer, TrainingArguments\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Custom Callback that inherits from TrainerCallback.\n",
    "    Used to make an evaluation on the training data also.\n",
    "    \"\"\"\n",
    "    def __init__(self, trainer: Trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments were taken from the internet\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"output-models\",\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    logging_dir=\"logs\",\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wish at the end of each epoch to view results\n",
    "# on the training set also, change this flag to True.\n",
    "# Note: doing so will result in a longer training time.\n",
    "\n",
    "evaluate_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_valid,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "if evaluate_train:\n",
    "    trainer.add_callback(CustomCallback(trainer)) \n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(ds_test)\n",
    "preds.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Precision-Recall curves to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Calculate probabilities from the predictions output\n",
    "preds_probs = F.softmax(torch.Tensor(preds.predictions), dim=1)\n",
    "\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    \"\"\"\n",
    "    Takes in a \"class_index\" from 0 to 99 and plots the corresponding\n",
    "    precision-recall curve in the tensorboard.\n",
    "    \"\"\"\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(\n",
    "        tag=id2label[class_index],\n",
    "        labels=tensorboard_truth,\n",
    "        predictions=tensorboard_probs,\n",
    "        global_step=global_step\n",
    "        )\n",
    "    writer.close()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, preds_probs, preds.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(ds_test)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best model and training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
